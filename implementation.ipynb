{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (1.24.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: ucimlrepo in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (0.0.3)\n",
      "Requirement already satisfied: lime in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (0.2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from lime) (3.8.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from lime) (4.65.0)\n",
      "Requirement already satisfied: scikit-image>=0.12 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from lime) (0.21.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from scikit-image>=0.12->lime) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from scikit-image>=0.12->lime) (10.0.1)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from scikit-image>=0.12->lime) (2.31.3)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from scikit-image>=0.12->lime) (2023.8.30)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from scikit-image>=0.12->lime) (1.4.1)\n",
      "Requirement already satisfied: packaging>=21 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from scikit-image>=0.12->lime) (23.1)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from scikit-image>=0.12->lime) (0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from matplotlib->lime) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from matplotlib->lime) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from matplotlib->lime) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from matplotlib->lime) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from matplotlib->lime) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from tqdm->lime) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\ProgramData\\Anaconda3\\envs\\torchnew\\Lib\\site-packages\\numpy-1.26.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\ProgramData\\Anaconda3\\envs\\torchnew\\Lib\\site-packages\\numpy-1.26.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\ProgramData\\Anaconda3\\envs\\torchnew\\Lib\\site-packages\\numpy-1.26.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\ProgramData\\Anaconda3\\envs\\torchnew\\Lib\\site-packages\\numpy-1.26.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\ProgramData\\Anaconda3\\envs\\torchnew\\Lib\\site-packages\\numpy-1.26.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\ProgramData\\Anaconda3\\envs\\torchnew\\Lib\\site-packages\\numpy-1.26.0.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy scikit-learn ucimlrepo lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, Normalizer, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import uniform, norm\n",
    "from scipy.special import softmax\n",
    "import shap\n",
    "\n",
    "MODEL_NAME = 'Wine'\n",
    "\n",
    "MODEL_FUNCTION = DecisionTreeClassifier\n",
    "model_params = {}\n",
    "coding = {\"Wine\": 109}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "split_size = 0.3\n",
    "seed = 1234567\n",
    "\n",
    "dataset_id = coding[MODEL_NAME]\n",
    "\n",
    "wine = fetch_ucirepo(id=109) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data (as pandas dataframes) \n",
    "X = wine.data.features\n",
    "y = wine.data.targets.to_numpy()\n",
    "y = y.reshape((len(y), ))\n",
    "    \n",
    "\n",
    "n_classes = len(np.unique(y))\n",
    "n_feats = X.shape[1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = split_size, random_state = seed)\n",
    "\n",
    "normalizer = Normalizer().fit(x_train)\n",
    "encoder = LabelEncoder().fit(y_train)\n",
    "\n",
    "x_train = normalizer.transform(x_train)\n",
    "x_test = normalizer.transform(x_test)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test  = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, samples, targets):\n",
    "    pred = model.predict(samples)\n",
    "    return accuracy_score(targets, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "model = MODEL_FUNCTION(*model_params, random_state= 1234567)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "acc_train = evaluate_model(model, x_train, y_train)\n",
    "acc_test  = evaluate_model(model, x_test, y_test)\n",
    "\n",
    "print(acc_train, acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shap_feature_importances(model, x_train):\n",
    "    '''Get scores with shap'''\n",
    "    se = shap.Explainer(model)\n",
    "    shap_values = se.shap_values(x_train)\n",
    "    importance_order = np.argsort(-abs(np.abs(np.array(shap_values)).mean(axis = 1).mean(axis = 0)))\n",
    "    importances = np.abs(np.array(shap_values)).mean(axis = 1).mean(axis = 0)[importance_order]\n",
    "    return importance_order, importances\n",
    "\n",
    "order, importances = get_shap_feature_importances(model, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Local2GlobalExplainer:\n",
    "    def __init__(self, x_train, model, n_classes):\n",
    "        '''Initialization function for Local2GlobalExplainer\n",
    "        \n",
    "        Arguments:\n",
    "        1. x_train: training data\n",
    "        2. model: the model to run explanations for\n",
    "        3. n_classes: number of classes'''\n",
    "        self.model = model\n",
    "        self.data = x_train\n",
    "        \n",
    "        # LIME model\n",
    "        self.explainer = lime_tabular.LimeTabularExplainer(\n",
    "            training_data=self.data, \n",
    "            mode = 'classification'     \n",
    "            )\n",
    "        \n",
    "        \n",
    "        # cached mcmc explanations\n",
    "        self.mcmc_explanations = None\n",
    "        self.mcmc_agg = None\n",
    "        \n",
    "        # cached importance sampling explanations\n",
    "        self.imp_explanations = None\n",
    "        self.imp_agg = None\n",
    "        \n",
    "        # fitting a gaussian mixture model to take care of multimodal data\n",
    "        self.gmm = BayesianGaussianMixture(n_components = n_classes*2).fit(x_train)\n",
    "        \n",
    "    def get_optimal_gmm(n_components):\n",
    "        '''Helper function \n",
    "        \n",
    "        **UNUSED**\n",
    "        \n",
    "        '''\n",
    "        c = round(n_components)\n",
    "        gmm = GaussianMixture(n_components = c).fit(x_train)\n",
    "        return gmm.bic(x_train)\n",
    "        \n",
    "    def get_local_interpretation(self, sample):\n",
    "        '''Function to get LIME interpretations for a sample\n",
    "        \n",
    "        Arguments:\n",
    "        1. sample: the incoming sample\n",
    "        2. num_features: number of features to '''\n",
    "        exp = self.explainer.explain_instance(sample, self.model.predict_proba, num_features = len(sample))\n",
    "        local_exp = list(exp.local_exp.values())[0]\n",
    "        local_exp = sorted(local_exp)\n",
    "        \n",
    "        explanations = [x[1] for x in local_exp]\n",
    "        return explanations\n",
    "    \n",
    "    def rank_explanations(self, explanations):\n",
    "        '''Helper function to rank explanations sorted in the order of highest magnitude to lowest magnitude\n",
    "        \n",
    "        Arguments:\n",
    "        1. explanations: aggregated explanations\n",
    "        \n",
    "        Returns:\n",
    "        1. sorted list for explanations with feat indices and corresponding importances'''\n",
    "        return sorted(list(zip(range(len(explanations)), explanations)), key = lambda x: -abs(x[1]))\n",
    "    \n",
    "    def get_only_feature_importance(self, explanations):\n",
    "        '''Helper function to only get features\n",
    "        \n",
    "        Arguments:\n",
    "        1. explanations: aggregated explanations\n",
    "        \n",
    "        Returns:\n",
    "        1. Sorted list for explanations with just feature indices'''\n",
    "        ranks = self.rank_explanations(explanations)\n",
    "        return [x[0] for x in ranks]\n",
    "    \n",
    "    def mcmc_estimate(self, num_samples):\n",
    "        '''Function to run Markov chain Monte Carlo approx based explanations. Samples q(x) from a standard normal distribution\n",
    "        \n",
    "        Arguments:\n",
    "        1. num_samples: number of samples to sample from\n",
    "        \n",
    "        Returns:\n",
    "        1. agg_explanations: an array containing aggregated explanations\n",
    "        2. explanations: explanations for each sample'''\n",
    "        samples, gmm_class = self.gmm.sample(num_samples)       # generate samples from the fit gmm\n",
    "        explanations = []                                       # list to store explanations\n",
    "        for sample in tqdm(samples):\n",
    "            interpret = np.array(self.get_local_interpretation(sample))\n",
    "            # sigmoid_interpretation = self.get_scores(interpret)\n",
    "            explanations.append(interpret)\n",
    "            \n",
    "        agg_explanations = np.mean(np.array(explanations), axis = 0)        # aggregating\n",
    "        \n",
    "        self.mcmc_agg = explanations\n",
    "        self.agg_explanations = agg_explanations\n",
    "        return agg_explanations, explanations\n",
    "    \n",
    "    def get_scores(self, ex):\n",
    "        '''Function to normalize scores using a softmax function multiplied by correlation signs'''\n",
    "        signs = np.sign(ex)\n",
    "        abs_softmax = softmax(np.abs(ex))\n",
    "        return abs_softmax*signs\n",
    "    \n",
    "    def importance_sampling(self, num_samples):\n",
    "        '''Function to run importance sampling for explanations. Samples q(x) from a standard normal distribution\n",
    "        \n",
    "        Arguments:\n",
    "        1. num_samples: number of samples to sample from\n",
    "        \n",
    "        Returns:\n",
    "        1. agg_explanations: an array containing aggregated explanations\n",
    "        2. explanations: explanations for each sample'''\n",
    "        q = np.random.randn(num_samples)\n",
    "        samples, gmm_class = self.gmm.sample(num_samples)       # generate samples from the fit gmm\n",
    "        scores = np.exp(self.gmm.score_samples(samples))        # p(x)\n",
    "        qx = norm.pdf(q)                                        # q(x)\n",
    "        \n",
    "        importance = scores/qx\n",
    "        explanations = []\n",
    "        \n",
    "        for i in tqdm(range(num_samples)):\n",
    "            interpret = np.array(self.get_local_interpretation(samples[i]))\n",
    "            # sigmoid_interpretation = self.get_scores(interpret)\n",
    "            importance_weighted_interpretation = interpret*importance[i]\n",
    "            explanations.append(importance_weighted_interpretation)\n",
    "            \n",
    "        agg_explanations = np.mean(np.array(explanations), axis = 0)\n",
    "        self.imp_explanations = explanations\n",
    "        self.imp_agg = agg_explanations\n",
    "        \n",
    "        return agg_explanations, explanations\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_feats_removed(x_train, y_train, x_test, y_test, n_feats, feat_indices, k = 4, trials = 15):\n",
    "    selected_feats = list(set(np.arange(n_feats)).difference(feat_indices[:k]))      # exclude top k features\n",
    "    x_t = x_train[:, selected_feats]\n",
    "    x_tst = x_test[:, selected_feats]\n",
    "    \n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    \n",
    "    for i in range(trials):\n",
    "\n",
    "        m = MODEL_FUNCTION(*model_params).fit(x_t, y_train)\n",
    "        acc_train = evaluate_model(m, x_t, y_train)\n",
    "        acc_test  = evaluate_model(m, x_tst, y_test)\n",
    "        \n",
    "        train_accs.append(acc_train)\n",
    "        test_accs.append(acc_test)\n",
    "        \n",
    "    train_accs, test_accs = np.array(train_accs), np.array(test_accs)\n",
    "    \n",
    "    return {'train_acc': train_accs.mean(),\n",
    "            'train_var': train_accs.var(),\n",
    "            'test_acc': test_accs.mean(),\n",
    "            'test_var': test_accs.var()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local2Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:07<00:00, 63.36it/s]\n",
      "100%|██████████| 500/500 [00:07<00:00, 64.16it/s]\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "\n",
    "num_trials = 500\n",
    "\n",
    "#shap\n",
    "order_shap, _ = get_shap_feature_importances(model, x_train)\n",
    "\n",
    "#fit\n",
    "l2g_exp = Local2GlobalExplainer(x_train, model, n_classes)\n",
    "mc_exp, _ = l2g_exp.mcmc_estimate(num_trials)\n",
    "is_exp, _ = l2g_exp.importance_sampling(num_trials)\n",
    "\n",
    "#order calculation\n",
    "order_mc = l2g_exp.get_only_feature_importance(mc_exp)\n",
    "order_is = l2g_exp.get_only_feature_importance(is_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats_removed_limit = 5\n",
    "trials = 15\n",
    "\n",
    "scores = pd.DataFrame()\n",
    "\n",
    "for rem_feats in range(1, num_feats_removed_limit+1):\n",
    "    shap_scores =  evaluate_model_feats_removed(x_train, y_train, x_test, y_test, n_feats, order_shap, k = rem_feats, trials = trials)\n",
    "    s_df = pd.DataFrame(shap_scores, index = [0])\n",
    "    s_df['Method'] = 'SHAP'\n",
    "    s_df['Features_removed'] = rem_feats\n",
    "    \n",
    "    mc_scores =  evaluate_model_feats_removed(x_train, y_train, x_test, y_test, n_feats, order_mc, k = rem_feats, trials = trials)\n",
    "    mc_df = pd.DataFrame(mc_scores, index = [0])\n",
    "    mc_df['Method'] = 'MCMC'\n",
    "    mc_df['Features_removed'] = rem_feats\n",
    "    \n",
    "    is_scores =  evaluate_model_feats_removed(x_train, y_train, x_test, y_test, n_feats, order_is, k = rem_feats, trials = trials)\n",
    "    is_df = pd.DataFrame(is_scores, index = [0])\n",
    "    is_df['Method'] = 'Importance Sampling'\n",
    "    is_df['Features_removed'] = rem_feats\n",
    "    \n",
    "    \n",
    "    scores = pd.concat([scores, s_df, mc_df, is_df], axis = 0)\n",
    "\n",
    "scores = scores.reset_index(drop = True)[['Features_removed', 'Method', 'train_acc', 'train_var', 'test_acc', 'test_var']]\n",
    "scores = scores.sort_values(['Features_removed', 'Method', 'test_acc']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features_removed</th>\n",
       "      <th>Method</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_var</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Importance Sampling</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.949383</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MCMC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.951852</td>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.948148</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Importance Sampling</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.906173</td>\n",
       "      <td>0.000479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>MCMC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.862963</td>\n",
       "      <td>0.000905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.000823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>Importance Sampling</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.893827</td>\n",
       "      <td>0.000753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>MCMC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.859259</td>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.819753</td>\n",
       "      <td>0.000707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>Importance Sampling</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.000137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>MCMC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.861728</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.861728</td>\n",
       "      <td>0.000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>Importance Sampling</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.780247</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>MCMC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.843210</td>\n",
       "      <td>0.000543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Features_removed               Method  train_acc  train_var  test_acc  \\\n",
       "0                  1  Importance Sampling        1.0        0.0  0.949383   \n",
       "1                  1                 MCMC        1.0        0.0  0.951852   \n",
       "2                  1                 SHAP        1.0        0.0  0.948148   \n",
       "3                  2  Importance Sampling        1.0        0.0  0.906173   \n",
       "4                  2                 MCMC        1.0        0.0  0.862963   \n",
       "5                  2                 SHAP        1.0        0.0  0.907407   \n",
       "6                  3  Importance Sampling        1.0        0.0  0.893827   \n",
       "7                  3                 MCMC        1.0        0.0  0.859259   \n",
       "8                  3                 SHAP        1.0        0.0  0.819753   \n",
       "9                  4  Importance Sampling        1.0        0.0  0.888889   \n",
       "10                 4                 MCMC        1.0        0.0  0.861728   \n",
       "11                 4                 SHAP        1.0        0.0  0.861728   \n",
       "12                 5  Importance Sampling        1.0        0.0  0.780247   \n",
       "13                 5                 MCMC        1.0        0.0  0.843210   \n",
       "14                 5                 SHAP        1.0        0.0  0.851852   \n",
       "\n",
       "    test_var  \n",
       "0   0.000067  \n",
       "1   0.000082  \n",
       "2   0.000055  \n",
       "3   0.000479  \n",
       "4   0.000905  \n",
       "5   0.000823  \n",
       "6   0.000753  \n",
       "7   0.000082  \n",
       "8   0.000707  \n",
       "9   0.000137  \n",
       "10  0.000085  \n",
       "11  0.000314  \n",
       "12  0.000223  \n",
       "13  0.000543  \n",
       "14  0.000183  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.to_csv(f\"benchmarks_{MODEL_NAME}.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('torchnew')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aae2c75324e7fdf5ebd22146e2daffaa477f8ea149f0e685be4c317c2939a685"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
