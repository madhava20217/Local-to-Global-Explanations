{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (1.24.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: ucimlrepo in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (0.0.3)\n",
      "Requirement already satisfied: lime in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (0.2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from lime) (3.8.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from lime) (4.65.0)\n",
      "Requirement already satisfied: scikit-image>=0.12 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from lime) (0.21.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from scikit-image>=0.12->lime) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from scikit-image>=0.12->lime) (10.0.1)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from scikit-image>=0.12->lime) (2.31.3)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from scikit-image>=0.12->lime) (2023.8.30)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from scikit-image>=0.12->lime) (1.4.1)\n",
      "Requirement already satisfied: packaging>=21 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from scikit-image>=0.12->lime) (23.1)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from scikit-image>=0.12->lime) (0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from matplotlib->lime) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from matplotlib->lime) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from matplotlib->lime) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from matplotlib->lime) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from matplotlib->lime) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\torchnew\\lib\\site-packages (from tqdm->lime) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\ProgramData\\Anaconda3\\envs\\torchnew\\Lib\\site-packages\\numpy-1.26.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\ProgramData\\Anaconda3\\envs\\torchnew\\Lib\\site-packages\\numpy-1.26.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\ProgramData\\Anaconda3\\envs\\torchnew\\Lib\\site-packages\\numpy-1.26.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\ProgramData\\Anaconda3\\envs\\torchnew\\Lib\\site-packages\\numpy-1.26.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\ProgramData\\Anaconda3\\envs\\torchnew\\Lib\\site-packages\\numpy-1.26.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\ProgramData\\Anaconda3\\envs\\torchnew\\Lib\\site-packages\\numpy-1.26.0.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy scikit-learn ucimlrepo lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, Normalizer, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import uniform, norm\n",
    "from scipy.special import softmax\n",
    "import shap\n",
    "\n",
    "MODEL_NAME = 'Wine'\n",
    "\n",
    "MODEL_FUNCTION = DecisionTreeClassifier\n",
    "model_params = {'random_state': 1340304}\n",
    "\n",
    "coding = {\"Wine\": 109, 'German Credit': 144}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "split_size = 0.3\n",
    "seed = 1234567\n",
    "\n",
    "dataset_id = coding[MODEL_NAME]\n",
    "\n",
    "wine = fetch_ucirepo(id=109) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data (as pandas dataframes) \n",
    "X = wine.data.features\n",
    "y = wine.data.targets.to_numpy()\n",
    "y = y.reshape((len(y), ))\n",
    "    \n",
    "\n",
    "n_classes = len(np.unique(y))\n",
    "n_feats = X.shape[1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = split_size, random_state = seed)\n",
    "\n",
    "normalizer = Normalizer().fit(x_train)\n",
    "encoder = LabelEncoder().fit(y_train)\n",
    "\n",
    "x_train = normalizer.transform(x_train)\n",
    "x_test = normalizer.transform(x_test)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test  = encoder.transform(y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, samples, targets):\n",
    "    pred = model.predict(samples)\n",
    "    return accuracy_score(targets, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "model = MODEL_FUNCTION(**model_params)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "acc_train = evaluate_model(model, x_train, y_train)\n",
    "acc_test  = evaluate_model(model, x_test, y_test)\n",
    "\n",
    "print(acc_train, acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b9f1beac764876b1a81fe0f3a0f93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_shap_feature_importances(model, x_train):\n",
    "    '''Get scores with shap'''\n",
    "    samples = np.random.choice(list(range(len(x_train))), min(5, len(x_train)), replace = False)\n",
    "    se = shap.KernelExplainer(model.predict, x_train[samples])\n",
    "    shap_values = se.shap_values(x_train)\n",
    "    importance_order = np.argsort(-abs(np.abs(np.array(shap_values)).mean(axis = 0)))\n",
    "    importances = np.abs(np.array(shap_values)).mean(axis = 0)[importance_order]\n",
    "    return importance_order, importances\n",
    "\n",
    "order, importances = get_shap_feature_importances(model, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Local2GlobalExplainer:\n",
    "    def __init__(self, x_train, model, n_classes, components = n_classes*4):\n",
    "        '''Initialization function for Local2GlobalExplainer\n",
    "        \n",
    "        Arguments:\n",
    "        1. x_train: training data\n",
    "        2. model: the model to run explanations for\n",
    "        3. n_classes: number of classes'''\n",
    "        self.model = model\n",
    "        self.data = x_train\n",
    "        \n",
    "        # LIME model\n",
    "        self.explainer = lime_tabular.LimeTabularExplainer(\n",
    "            training_data=self.data, \n",
    "            mode = 'classification'     \n",
    "            )\n",
    "        \n",
    "        \n",
    "        # cached mcmc explanations\n",
    "        self.mcmc_explanations = None\n",
    "        self.mcmc_agg = None\n",
    "        \n",
    "        # cached importance sampling explanations\n",
    "        self.imp_explanations = None\n",
    "        self.imp_agg = None\n",
    "        \n",
    "        # fitting a gaussian mixture model to take care of multimodal data\n",
    "        self.gmm = BayesianGaussianMixture(n_components = components).fit(x_train)\n",
    "        \n",
    "    def get_optimal_gmm(n_components):\n",
    "        '''Helper function \n",
    "        \n",
    "        **UNUSED**\n",
    "        \n",
    "        '''\n",
    "        c = round(n_components)\n",
    "        gmm = GaussianMixture(n_components = c).fit(x_train)\n",
    "        return gmm.bic(x_train)\n",
    "        \n",
    "    def get_local_interpretation(self, sample):\n",
    "        '''Function to get LIME interpretations for a sample\n",
    "        \n",
    "        Arguments:\n",
    "        1. sample: the incoming sample\n",
    "        2. num_features: number of features to '''\n",
    "        exp = self.explainer.explain_instance(sample, self.model.predict_proba, num_features = len(sample))\n",
    "        local_exp = list(exp.local_exp.values())[0]\n",
    "        local_exp = sorted(local_exp)\n",
    "        \n",
    "        explanations = [x[1] for x in local_exp]\n",
    "        return explanations\n",
    "    \n",
    "    def rank_explanations(self, explanations):\n",
    "        '''Helper function to rank explanations sorted in the order of highest magnitude to lowest magnitude\n",
    "        \n",
    "        Arguments:\n",
    "        1. explanations: aggregated explanations\n",
    "        \n",
    "        Returns:\n",
    "        1. sorted list for explanations with feat indices and corresponding importances'''\n",
    "        return sorted(list(zip(range(len(explanations)), explanations)), key = lambda x: -abs(x[1]))\n",
    "    \n",
    "    def get_only_feature_importance(self, explanations):\n",
    "        '''Helper function to only get features\n",
    "        \n",
    "        Arguments:\n",
    "        1. explanations: aggregated explanations\n",
    "        \n",
    "        Returns:\n",
    "        1. Sorted list for explanations with just feature indices'''\n",
    "        ranks = self.rank_explanations(explanations)\n",
    "        return [x[0] for x in ranks]\n",
    "    \n",
    "    def mcmc_estimate(self, num_samples):\n",
    "        '''Function to run Markov chain Monte Carlo approx based explanations. Samples q(x) from a standard normal distribution\n",
    "        \n",
    "        Arguments:\n",
    "        1. num_samples: number of samples to sample from\n",
    "        \n",
    "        Returns:\n",
    "        1. agg_explanations: an array containing aggregated explanations\n",
    "        2. explanations: explanations for each sample'''\n",
    "        samples, gmm_class = self.gmm.sample(num_samples)       # generate samples from the fit gmm\n",
    "        explanations = []                                       # list to store explanations\n",
    "        for sample in tqdm(samples):\n",
    "            interpret = np.array(self.get_local_interpretation(sample))\n",
    "            # sigmoid_interpretation = self.get_scores(interpret)\n",
    "            interpret = np.abs(interpret)\n",
    "            explanations.append(interpret)\n",
    "            \n",
    "        agg_explanations = np.mean(np.array(explanations), axis = 0)        # aggregating\n",
    "        \n",
    "        self.mcmc_agg = explanations\n",
    "        self.agg_explanations = agg_explanations\n",
    "        return agg_explanations, explanations\n",
    "    \n",
    "    def get_scores(self, ex):\n",
    "        '''Function to normalize scores using a softmax function multiplied by correlation signs'''\n",
    "        signs = np.sign(ex)\n",
    "        abs_softmax = softmax(np.abs(ex))\n",
    "        return abs_softmax*signs\n",
    "    \n",
    "    def importance_sampling(self, num_samples):\n",
    "        '''Function to run importance sampling for explanations. Samples q(x) from a standard normal distribution\n",
    "        \n",
    "        Arguments:\n",
    "        1. num_samples: number of samples to sample from\n",
    "        \n",
    "        Returns:\n",
    "        1. agg_explanations: an array containing aggregated explanations\n",
    "        2. explanations: explanations for each sample'''\n",
    "        q = np.random.randn(num_samples)\n",
    "        samples, gmm_class = self.gmm.sample(num_samples)       # generate samples from the fit gmm\n",
    "        scores = np.exp(self.gmm.score_samples(samples))        # p(x)\n",
    "        qx = norm.pdf(q)                                        # q(x)\n",
    "        \n",
    "        importance = scores/qx\n",
    "        explanations = []\n",
    "        \n",
    "        for i in tqdm(range(num_samples)):\n",
    "            interpret = np.array(self.get_local_interpretation(samples[i]))\n",
    "            # sigmoid_interpretation = self.get_scores(interpret)\n",
    "            importance_weighted_interpretation = np.abs(interpret*importance[i])\n",
    "            explanations.append(importance_weighted_interpretation)\n",
    "            \n",
    "        agg_explanations = np.mean(np.array(explanations), axis = 0)\n",
    "        self.imp_explanations = explanations\n",
    "        self.imp_agg = agg_explanations\n",
    "        \n",
    "        return agg_explanations, explanations\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_feats_removed(x_train, y_train, x_test, y_test, n_feats, feat_indices, k = 4, trials = 15):\n",
    "    selected_feats = list(set(np.arange(n_feats)).difference(feat_indices[:k]))      # exclude top k features\n",
    "    x_t = x_train[:, selected_feats]\n",
    "    x_tst = x_test[:, selected_feats]\n",
    "    \n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    \n",
    "    for i in range(trials):\n",
    "\n",
    "        m = MODEL_FUNCTION(**model_params).fit(x_t, y_train)\n",
    "        acc_train = evaluate_model(m, x_t, y_train)\n",
    "        acc_test  = evaluate_model(m, x_tst, y_test)\n",
    "        \n",
    "        train_accs.append(acc_train)\n",
    "        test_accs.append(acc_test)\n",
    "\n",
    "        \n",
    "    train_accs, test_accs = np.array(train_accs), np.array(test_accs)\n",
    "    \n",
    "    return {'train_acc': train_accs.mean(),\n",
    "            'train_var': train_accs.var(),\n",
    "            'test_acc': test_accs.mean(),\n",
    "            'test_var': test_accs.var()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local2Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55eac0938d34559883bee21af01f876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:07<00:00, 63.85it/s]\n",
      "100%|██████████| 500/500 [00:07<00:00, 63.32it/s]\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "\n",
    "num_trials = 500\n",
    "\n",
    "#shap\n",
    "order_shap, _ = get_shap_feature_importances(model, x_train)\n",
    "\n",
    "#fit\n",
    "l2g_exp = Local2GlobalExplainer(x_train, model, n_classes)\n",
    "mc_exp, _ = l2g_exp.mcmc_estimate(num_trials)\n",
    "is_exp, _ = l2g_exp.importance_sampling(num_trials)\n",
    "\n",
    "#order calculation\n",
    "order_mc = l2g_exp.get_only_feature_importance(mc_exp)\n",
    "order_is = l2g_exp.get_only_feature_importance(is_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>(SHAP) Test acc</th>\n",
       "      <th>(SHAP) Test var</th>\n",
       "      <th>(MCMC) Test acc</th>\n",
       "      <th>(MCMC) Test var</th>\n",
       "      <th>(Imp. Samp.) Test acc</th>\n",
       "      <th>(Imp. Samp.) Test var</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Features Removed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wine</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wine</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>4.930381e-32</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>1.232595e-32</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>1.232595e-32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wine</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>4.930381e-32</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>4.930381e-32</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>4.930381e-32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wine</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>4.930381e-32</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>4.930381e-32</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>1.232595e-32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wine</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>4.930381e-32</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.232595e-32</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.232595e-32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wine</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>4.930381e-32</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>4.930381e-32</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>4.930381e-32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dataset  (SHAP) Test acc  (SHAP) Test var  (MCMC) Test acc  \\\n",
       "Features Removed                                                              \n",
       "1                   Wine         0.944444     0.000000e+00         0.944444   \n",
       "2                   Wine         0.925926     4.930381e-32         0.870370   \n",
       "3                   Wine         0.907407     4.930381e-32         0.851852   \n",
       "4                   Wine         0.851852     4.930381e-32         0.851852   \n",
       "5                   Wine         0.833333     4.930381e-32         0.888889   \n",
       "6                   Wine         0.833333     4.930381e-32         0.833333   \n",
       "\n",
       "                  (MCMC) Test var  (Imp. Samp.) Test acc  \\\n",
       "Features Removed                                           \n",
       "1                    0.000000e+00               0.944444   \n",
       "2                    1.232595e-32               0.981481   \n",
       "3                    4.930381e-32               0.851852   \n",
       "4                    4.930381e-32               0.870370   \n",
       "5                    1.232595e-32               0.888889   \n",
       "6                    4.930381e-32               0.851852   \n",
       "\n",
       "                  (Imp. Samp.) Test var  \n",
       "Features Removed                         \n",
       "1                          0.000000e+00  \n",
       "2                          1.232595e-32  \n",
       "3                          4.930381e-32  \n",
       "4                          1.232595e-32  \n",
       "5                          1.232595e-32  \n",
       "6                          4.930381e-32  "
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_feats_removed_limit = 6\n",
    "trials = 100\n",
    "\n",
    "scores = pd.DataFrame()\n",
    "\n",
    "for rem_feats in range(1, num_feats_removed_limit+1):\n",
    "    shap_scores =  evaluate_model_feats_removed(x_train, y_train, x_test, y_test, n_feats, order_shap, k = rem_feats, trials = trials)\n",
    "    s_df = pd.DataFrame(shap_scores, index = [0])\n",
    "    s_df = s_df.drop(columns = ['train_acc', 'train_var']).rename(columns = {'test_acc': '(SHAP) Test acc', 'test_var': '(SHAP) Test var'})\n",
    "    \n",
    "    mc_scores =  evaluate_model_feats_removed(x_train, y_train, x_test, y_test, n_feats, order_mc, k = rem_feats, trials = trials)\n",
    "    mc_df = pd.DataFrame(mc_scores, index = [0])\n",
    "    mc_df =mc_df.drop(columns = ['train_acc', 'train_var']).rename(columns = {'test_acc': '(MCMC) Test acc', 'test_var': '(MCMC) Test var'})\n",
    "    \n",
    "    \n",
    "    is_scores =  evaluate_model_feats_removed(x_train, y_train, x_test, y_test, n_feats, order_is, k = rem_feats, trials = trials)\n",
    "    is_df = pd.DataFrame(is_scores, index = [0])\n",
    "    is_df = is_df.drop(columns = ['train_acc', 'train_var']).rename(columns = {'test_acc': '(Imp. Samp.) Test acc', 'test_var': '(Imp. Samp.) Test var'})\n",
    "    \n",
    "    \n",
    "    test = pd.concat([s_df, mc_df, is_df], axis = 1)\n",
    "    test['Features Removed'] = rem_feats\n",
    "    \n",
    "    scores = pd.concat([scores, test], axis = 0)\n",
    "\n",
    "scores = scores.reset_index(drop = True)\n",
    "scores['Dataset'] = MODEL_NAME\n",
    "\n",
    "order = list(scores.columns[-2:]) + list(scores.columns[:-2])\n",
    "scores = scores[order].set_index(\"Features Removed\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.to_csv(f\"benchmarks_{MODEL_NAME}.csv\", index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('torchnew')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aae2c75324e7fdf5ebd22146e2daffaa477f8ea149f0e685be4c317c2939a685"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
