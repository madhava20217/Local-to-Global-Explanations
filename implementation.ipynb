{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import lime\n",
    "from lime import lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "split_size = 0.3\n",
    "seed = 1234567\n",
    "\n",
    "wine = fetch_ucirepo(id=109) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = wine.data.features \n",
    "y = wine.data.targets \n",
    "\n",
    "n_classes = len(y['class'].unique())\n",
    "n_feats = X.shape[1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = split_size, random_state = seed)\n",
    "\n",
    "normalizer = Normalizer().fit(x_train)\n",
    "encoder = OneHotEncoder().fit(y_train)\n",
    "\n",
    "x_train = normalizer.transform(x_train)\n",
    "x_test = normalizer.transform(x_test)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test  = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes, n_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x, y):\n",
    "    pred = model.predict(x)\n",
    "    return accuracy_score(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5967741935483871 0.6296296296296297\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier((n_feats, 256, n_classes),\n",
    "                      activation = 'relu',\n",
    "                      learning_rate = 'adaptive', \n",
    "                      learning_rate_init=0.029, \n",
    "                      max_iter = 1000,\n",
    "                      random_state=3)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "acc_train = evaluate_model(model, x_train, y_train)\n",
    "acc_test  = evaluate_model(model, x_test, y_test)\n",
    "\n",
    "print(acc_train, acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58010298, 0.08305055, 0.30143897]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x_test[0][None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\torchnew\\Lib\\site-packages\\lime\\lime_tabular.py:372: UserWarning: \n",
      "                    Prediction probabilties do not sum to 1, and\n",
      "                    thus does not constitute a probability space.\n",
      "                    Check that you classifier outputs probabilities\n",
      "                    (Not log probabilities, or actual class predictions).\n",
      "                    \n",
      "  warnings.warn(\"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: [(9, -0.17519128813176663),\n",
       "  (3, 0.13046890719713095),\n",
       "  (8, 0.08373988277210624),\n",
       "  (1, 0.06959551144327851),\n",
       "  (10, -0.044298332563636036),\n",
       "  (4, -0.039539361982557454),\n",
       "  (6, 0.03625815822408123),\n",
       "  (2, -0.02122096046158452),\n",
       "  (12, -0.017440225062098837),\n",
       "  (5, -0.016577653516246144),\n",
       "  (7, -0.011555468068045539),\n",
       "  (11, -0.004529974451325677),\n",
       "  (0, 0.004214644864743017)]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer = lime_tabular.LimeTabularExplainer(\n",
    "    training_data = x_train,\n",
    "    mode = 'classification'\n",
    ")\n",
    "\n",
    "exp = explainer.explain_instance(x_test[1], model.predict_proba, num_features = n_feats)\n",
    "exp.local_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6546303687386007"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([abs(x[1]) for x in exp.local_exp[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# add bayesian hyperparameter optimization for finding optimal number of components in gaussian mixture model (https://www.run.ai/guides/hyperparameter-tuning/bayesian-hyperparameter-optimization)\n",
    "# do sampling and hyperparameter exstimation\n",
    "# https://www.mdpi.com/2673-2688/4/2/23#:~:text=Post%2Dhoc%20explanation%20methods%20can,of%20underlying%20black%2Dbox%20model.\n",
    "# https://arxiv.org/pdf/1907.03039.pdf\n",
    "# https://arxiv.org/pdf/2101.07685.pdf\n",
    "# https://proceedings.neurips.cc/paper_files/paper/2020/file/24aef8cb3281a2422a59b51659f1ad2e-Paper.pdf\n",
    "# https://www.analyticsvidhya.com/blog/2018/11/reinforcement-learning-introduction-monte-carlo-learning-openai-gym/\n",
    "# https://faculty.washington.edu/yenchic/21Sp_stat542/Lec3_Mixture.pdf\n",
    "# https://machinelearningmastery.com/probabilistic-model-selection-measures/\n",
    "# https://www.run.ai/guides/hyperparameter-tuning/bayesian-hyperparameter-optimization\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.mixture.BayesianGaussianMixture.html#sklearn.mixture.BayesianGaussianMixture\n",
    "# https://stats.stackexchange.com/questions/226834/sampling-from-a-mixture-of-two-gamma-distributions/226837#226837\n",
    "\n",
    "# https://github.com/marcotcr/lime/blob/master/lime/explanation.py\n",
    "# https://lime-ml.readthedocs.io/en/latest/lime.html#\n",
    "# https://www.analyticsvidhya.com/blog/2022/07/everything-you-need-to-know-about-lime/\n",
    "# https://github.com/msetzu/glocalx\n",
    "# https://drive.google.com/file/d/1gW7V4FyUj9vajrGbIkoa7mbbZn4xEbD6/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('torchnew')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aae2c75324e7fdf5ebd22146e2daffaa477f8ea149f0e685be4c317c2939a685"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
