{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import lime\n",
    "from lime import lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "split_size = 0.3\n",
    "seed = 1234567\n",
    "\n",
    "wine = fetch_ucirepo(id=109) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = wine.data.features \n",
    "y = wine.data.targets \n",
    "\n",
    "n_classes = len(y['class'].unique())\n",
    "n_feats = X.shape[1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = split_size, random_state = seed)\n",
    "\n",
    "normalizer = Normalizer().fit(x_train)\n",
    "encoder = OneHotEncoder().fit(y_train)\n",
    "\n",
    "x_train = normalizer.transform(x_train)\n",
    "x_test = normalizer.transform(x_test)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test  = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes, n_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x, y):\n",
    "    pred = model.predict(x)\n",
    "    return accuracy_score(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5967741935483871 0.6296296296296297\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier((n_feats, 256, n_classes),\n",
    "                      activation = 'relu',\n",
    "                      learning_rate = 'adaptive', \n",
    "                      learning_rate_init=0.029, \n",
    "                      max_iter = 1000,\n",
    "                      random_state=3)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "acc_train = evaluate_model(model, x_train, y_train)\n",
    "acc_test  = evaluate_model(model, x_test, y_test)\n",
    "\n",
    "print(acc_train, acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58010298, 0.08305055, 0.30143897]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x_test[0][None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\torchnew\\Lib\\site-packages\\lime\\lime_tabular.py:372: UserWarning: \n",
      "                    Prediction probabilties do not sum to 1, and\n",
      "                    thus does not constitute a probability space.\n",
      "                    Check that you classifier outputs probabilities\n",
      "                    (Not log probabilities, or actual class predictions).\n",
      "                    \n",
      "  warnings.warn(\"\"\"\n"
     ]
    }
   ],
   "source": [
    "explainer = lime_tabular.LimeTabularExplainer(\n",
    "    training_data = x_train,\n",
    "    mode = 'classification'\n",
    ")\n",
    "\n",
    "exp = explainer.explain_instance(x_test[1], model.predict_proba, num_features = n_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lime.explanation.Explanation at 0x22a8a87d890>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [(9, -0.15952170160613696),\n",
       "  (3, 0.1329458790044254),\n",
       "  (8, 0.060529083672368346),\n",
       "  (1, 0.05669195189524648),\n",
       "  (6, 0.04364641122087194),\n",
       "  (4, -0.04050503728340228),\n",
       "  (10, -0.03289478469555357),\n",
       "  (11, 0.01863731088836311),\n",
       "  (12, -0.016017932477405235),\n",
       "  (5, -0.013282552507836061),\n",
       "  (2, -0.01225830559414973),\n",
       "  (7, -0.006685688438323617),\n",
       "  (0, -0.006682622537938497)]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.local_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6002992618220212"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([abs(x[1]) for x in exp.local_exp[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# add bayesian hyperparameter optimization for finding optimal number of components in gaussian mixture model (https://www.run.ai/guides/hyperparameter-tuning/bayesian-hyperparameter-optimization)\n",
    "# do sampling and hyperparameter exstimation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('torchnew')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aae2c75324e7fdf5ebd22146e2daffaa477f8ea149f0e685be4c317c2939a685"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
