# TODOs

add bayesian hyperparameter optimization for finding optimal number of components in gaussian mixture model (https://www.run.ai/guides/hyperparameter-tuning/bayesian-hyperparameter-optimization)
do sampling and hyperparameter exstimation
https://www.mdpi.com/2673-2688/4/2/23#:~:text=Post%2Dhoc%20explanation%20methods%20can,of%20underlying%20black%2Dbox%20model.
https://arxiv.org/pdf/1907.03039.pdf
https://arxiv.org/pdf/2101.07685.pdf
https://proceedings.neurips.cc/paper_files/paper/2020/file/24aef8cb3281a2422a59b51659f1ad2e-Paper.pdf
https://www.analyticsvidhya.com/blog/2018/11/reinforcement-learning-introduction-monte-carlo-learning-openai-gym/
https://faculty.washington.edu/yenchic/21Sp_stat542/Lec3_Mixture.pdf
https://machinelearningmastery.com/probabilistic-model-selection-measures/
https://www.run.ai/guides/hyperparameter-tuning/bayesian-hyperparameter-optimization
https://scikit-learn.org/stable/modules/generated/sklearn.mixture.BayesianGaussianMixture.html#sklearn.mixture.BayesianGaussianMixture
https://stats.stackexchange.com/questions/226834/sampling-from-a-mixture-of-two-gamma-distributions/226837#226837

https://github.com/marcotcr/lime/blob/master/lime/explanation.py
https://lime-ml.readthedocs.io/en/latest/lime.html#
https://www.analyticsvidhya.com/blog/2022/07/everything-you-need-to-know-about-lime/
https://github.com/msetzu/glocalx
https://drive.google.com/file/d/1gW7V4FyUj9vajrGbIkoa7mbbZn4xEbD6/view


benchmarks
https://arxiv.org/pdf/2106.12543.pdf